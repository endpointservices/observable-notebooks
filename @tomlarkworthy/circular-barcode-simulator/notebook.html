<!doctype html>
<notebook theme="air">
  <title>Simplifying Pose Estimation with Circular Barcodes</title>
  <script id="0" type="text/markdown">
    # Simplifying Pose Estimation with Circular Barcodes
  </script>
  <script id="2736" type="text/markdown">
    A [decade](https://edinburghhacklab.com/2012/05/optical-localization-to-0-1mm-no-problemo/) ago I hoped to build low-cost, high-speed optical positioning for robots, using camera-based end effector measurements. However, the challenge lies in achieving high-frequency measurements comparable to those of commercial robot arms, which measure 10,000 times per second, far beyond the capabilities of affordable 30 frames per second digital cameras. Recent advancements have somewhat closed this gap: for instance, a Raspberry PI camera utilizing raspiraw can [reach 1007 frames-per-second](https://www.youtube.com/watch?v=m3Bs-yhWZ3M), providing a low-latency hardware solution.

    Still, the hurdle of fast pose estimation remains due to the inherent bandwidth intensity of computer vision. The difficulty lies in the variability of object appearances and the high dimensionality of the task, requiring a search for a 6DOF-oriented object in a 2D image plane. However, by redesigning the problem with circular barcodes, which can be read from any angle, we can transform a 2D recognition problem into a simpler 1D task that matches the camera's hardware interface better. This notebook presents a open-source simulator setup and a basic scan line-based template detector algorithm to confirm the geometric argument.
  </script>
  <script id="1767" type="text/markdown">
    ## Camera simulation

    This is our model of a camera built with [three.js](https://threejs.org/). You can pan and zoom with the mouse to alter the pose of the barcode relative to the camera.
  </script>
  <script id="2591" type="application/vnd.observable.javascript">
    viewof imageSource = Inputs.select(["real", "synthetic"], {
      label: "image"
    })
  </script>
  <script id="2363" type="application/vnd.observable.javascript">
    renderer = new THREE.WebGLRenderer({ antialias: true })
  </script>
  <script id="362" type="application/vnd.observable.javascript">
    render = {
      var renderTarget = new THREE.WebGLRenderTarget(width, height);
      const gl = renderer.getContext();
      const render = () => {
        renderer.setRenderTarget(renderTarget);
        renderer.render(scene, camera);
        gl.readPixels(0, 0, width, height, gl.RGBA, gl.UNSIGNED_BYTE, pixelBuffer);
        renderer.setRenderTarget(null);
        renderer.render(scene, camera);
        mutable renders++;
      };
      render.renderer = renderer;
      return render;
    }
  </script>
  <script id="360" type="application/vnd.observable.javascript">
    pixelBuffer = new Uint8Array(width * height * 4)
  </script>
  <script id="2353" type="application/vnd.observable.javascript">
    scene = {
      const textureLoader = new THREE.TextureLoader();
      let texture = undefined;
      if (imageSource == "real") {
        texture = textureLoader.load(await FileAttachment("image.png").url());
      } else {
        const blob = new Blob([synthetic.outerHTML], { type: "image/svg+xml" });
        const url = URL.createObjectURL(blob);
        texture = textureLoader.load(url);
      }

      const geometry = new THREE.BoxGeometry(1, 1, 1);
      await new Promise((res) => (textureLoader.manager.onLoad = res));
      const cube = new THREE.Mesh(
        geometry,
        new THREE.MeshBasicMaterial({ map: texture })
      );
      cube.position.x = -0.5;

      const scene = new THREE.Scene();
      scene.background = new THREE.Color(0x000);
      scene.add(cube);
      return scene;
    }
  </script>
  <script id="18" type="application/vnd.observable.javascript">
    camera = {
      const aspect = width / height;
      const near = 0.0001;
      const far = 1000;
      const camera = new THREE.PerspectiveCamera(fov, aspect, near, far);
      camera.position.set(1, 0, 1);
      camera.lookAt(new THREE.Vector3(0, 0, 0));
      return camera;
    }
  </script>
  <script id="1226" type="application/vnd.observable.javascript">
    viewof fov = Inputs.range([0, 180], {
      label: "field-of-view (degrees, vertical)",
      value: 45
    })
  </script>
  <script id="7" type="application/vnd.observable.javascript">
    canvas = {
      const controls = new THREE.OrbitControls(camera, renderer.domElement);
      invalidation.then(() => (controls.dispose(), renderer.dispose()));
      renderer.setSize(width, height);
      renderer.setPixelRatio(1);
      controls.addEventListener("change", render);
      render();
      return html`<div>${renderer.domElement}</div>`;
    }
  </script>
  <script id="423" type="application/vnd.observable.javascript">
    overlay = {
      const overlay = html`<svg width="${width}px" height="${height}px" style="z-index: 10; position: absolute; pointer-events: none;">
      <line x1="0" y1="${height - scanY}" x2="${width}" y2="${
        height - scanY
      }" stroke="red" />
    </svg>`;
      canvas.insertBefore(overlay, canvas.firstChild);
      invalidation.then(() => canvas.removeChild(overlay));
      return overlay;
    }
  </script>
  <script id="1773" type="text/markdown">
    ## Scan line sampler

    We expect to be able to recognize a barcode from a single scan that passes through the center of the barcode. Here you choose the scan line position and visualize the available signal.
  </script>
  <script id="446" type="application/vnd.observable.javascript">
    viewof scanY = Inputs.range([0, height], {
      label: "scanY",
      step: 1,
      value: 198
    })
  </script>
  <script id="2342" type="application/vnd.observable.javascript">
    scanline = {
      renders;
      const slice = pixelBuffer.slice(scanY * width * 4, (scanY + 1) * width * 4);

      return Array.from({ length: width }).map((_, i) => ({
        x: i,
        y: scanY,
        v: Math.round((slice[i * 4] + slice[i * 4 + 1] + slice[i * 4 + 2]) / 3)
      }));
    }
  </script>
  <script id="583" type="module">

  </script>
  <script id="660" type="text/markdown">
    ## Barcode Template

    We skip barcode decoding for now and concentrate on recognizing the *known* barcode pattern expressed as a binary string.
  </script>
  <script id="619" type="application/vnd.observable.javascript">
    template = {
      const half = [
        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,
        1, 1, 1
      ];
      return [...half, ...[...half].reverse()];
    }
  </script>
  <script id="628" type="application/vnd.observable.javascript">
    templateData = template.flatMap((v, i) => [
      { x: i, y: v },
      { x: i + 1, y: v }
    ])
  </script>
  <script id="631" type="module">

  </script>
  <script id="664" type="text/markdown">
    ## Projecting the template

    The barcode will appear somewhere in the scan line deformed by perspective geometry. Translation and scale are obvious, but more complex is the effect of orientation. Note an evenly spaced barcode will end up observed as a non-evenly spaced pattern due to vanishing distance effects
  </script>
  <script id="767" type="application/vnd.observable.javascript">
    image2 = FileAttachment("image@2.png").image({ width: 400 })
  </script>
  <script id="850" type="text/markdown">
    ## Pinhole Camera model 
  </script>
  <script id="2797" type="text/markdown">
    We can calculate the spacings by considering the angle that that the barcode is relative to the camera position.
  </script>
  <script id="804" type="application/vnd.observable.javascript">
    image5 = FileAttachment("image@5.png").image({ width: 400 })
  </script>
  <script id="813" type="text/markdown">

    ```
       cos(x) * c = cos(a) * b - d
       sin(x) * c = sin(a) * b
    => (eliminate c)
       (b * cos(a) - d) / cos(x) = (sin(a) * b) / sin(x)
    =>
       (b * cos(a)) / cos(x) - (sin(a) * b) / sin(x) = d / cos(x)
    => 
       b * (cos(a) / cos(x) - sin(a) / sin(x)) = d / cos(x)
    =>
       b = d / (cos(x) * (cos(a) / cos(x) - sin(a) / sin(x)))
    =>
       b = d / (cos(a) - sin(a) * cos(x) / sin(x))


    ```

  </script>
  <script id="2803" type="text/markdown">
    We eventually arrive at the conclusion the size of the barcode and the distance from the camera are the same thing. There are only 4 important parameters, one of which is the field-of-view which is fixed. So pose estimation on a scan line becomes a 3 dimensional problem.
  </script>
  <script id="681" type="application/vnd.observable.javascript">
    viewof offset_pinhole = Inputs.range([-0.5, 0.5], {
      label: "offset",
      value: 0
    })
  </script>
  <script id="1240" type="application/vnd.observable.javascript">
    viewof scale_pinhole = Inputs.range([0, 1.5], { label: "scale", value: 1 })
  </script>
  <script id="685" type="application/vnd.observable.javascript">
    viewof angle_pinhole = Inputs.range([-Math.PI, Math.PI], {
      label: "angle",
      value: 0
    })
  </script>
  <script id="2386" type="application/vnd.observable.javascript">
    viewof fov_pinhole = Inputs.range([0.00001, Math.PI], {
      label: "field-of-view (radians)",
      // three JS FOV is vertical which is related to horizontal via aspect ratio
      value:
        2 * Math.atan(Math.tan((camera.fov * Math.PI) / 180 / 2) * camera.aspect)
    })
  </script>
  <script id="2805" type="text/markdown">
    The pinhole model assumes the angle related directly to the pixel coordinates, which leads to very warped images. Real cameras project the angle to a flat plane sensor, which is what the angle correction toggle does below.
  </script>
  <script id="2654" type="application/vnd.observable.javascript">
    viewof useAngleCoorection = Inputs.toggle({
      label: "angle correction",
      value: true
    })
  </script>
  <script id="3087" type="application/vnd.observable.javascript">
    viewof useAngleCoorection1 = Inputs.toggle({
      label: "angle correction",
      value: true
    })
  </script>
  <script id="2812" type="text/markdown">
    With these parameters, we can simulate expected pixel values for a given projection on our image. Note how adjusting the angle creates the vanishing effect, and note how the field of view further modulates the effect. I have normalized all the params so it's easy to simulate in resolution-independant scales.
  </script>
  <script id="2394" type="application/vnd.observable.javascript">
    pinhole = (
      px,
      model = {
        angle: 0,
        offset: 0,
        scale: 1
      }
    ) => {
      const angleCorrection = (px) => {
        // flatten the image against an image plane, distance d from focal point
        // tan(angle) = opposite / adjacent
        // -fov / 2 is the extreme, -0.5 is extreme of image coords
        //    tan(-fov / 2) = -0.5 / d
        // => d = -0.5 / tan(-fov * 0.5)
        // Now we d we can go forward, preserving image coordinates
        const d = -0.5 / Math.tan(-0.5 * fov_pinhole);
        return Math.atan((px - model.offset) / d) / fov_pinhole;
      };
      const pinhole = (angle) => {
        if (!useAngleCoorection) angle -= model.offset;
        const x = angle * fov_pinhole; // range: [-0.5, -0.5]
        const a = model.angle + Math.PI / 2;
        const b = 0.5 / (Math.cos(a) - (Math.sin(a) * Math.cos(x)) / Math.sin(x));
        return (b / model.scale / fov_pinhole + 0.25) * templateData.length;
      };
      const imgCoord = useAngleCoorection ? angleCorrection(px) : px;
      return template[Math.round(pinhole(imgCoord))];
    }
  </script>
  <script id="675" type="module">

  </script>
  <script id="671" type="application/vnd.observable.javascript">
    projectedPinholeData = Array.from({ length: width }).map((_, x) => ({
      x: x,
      y: pinhole(x / width - 0.5, {
        offset: offset_pinhole,
        scale: scale_pinhole,
        angle: angle_pinhole
      })
    }))
  </script>
  <script id="1322" type="text/markdown">
    ## Estimate the goodness-of-fit of a proposed pose
  </script>
  <script id="2816" type="text/markdown">
    Given the camera model and the parameters of a template projection, we can measure the goodness-of-fit with the mean squared error of pixel intensities. This visualization is reactive to the parameters elsewhere in the notebook.
  </script>
  <script id="1345" type="application/vnd.observable.javascript">
    fitData = Array.from({ length: width }).map((_, x) => {
      const scan = scanline[x].v / 256;
      const template = pinhole(x / width - 0.5, {
        offset: offset_pinhole,
        scale: scale_pinhole,
        angle: angle_pinhole
      });
      const error = Math.pow(scan - template, 2);
      return {
        x: x,
        scan,
        template,
        error
      };
    })
  </script>
  <script id="1435" type="application/vnd.observable.javascript">
    meanError = d3.mean(fitData, (d) => d.error)
  </script>
  <script id="1660" type="application/vnd.observable.javascript">
    score_template_fit = (params = { offset: 0, scale: 1, angle: 0 }) => {
      let sumSquaredError = 0;
      for (let x = 0; x < width; x++) {
        const scan = scanline[x].v / 256;
        const template = pinhole(x / width - 0.5, {
          offset: params.offset,
          scale: params.scale,
          angle: params.angle
        });
        sumSquaredError += (scan - template) * (scan - template) || 1;
      }
      return sumSquaredError;
    }
  </script>
  <script id="2610" type="application/vnd.observable.javascript">
    viewof showTemplate = Inputs.toggle({
      label: "show template?",
      value: true
    })
  </script>
  <script id="2614" type="application/vnd.observable.javascript">
    viewof showScan = Inputs.toggle({
      label: "show scan?",
      value: true
    })
  </script>
  <script id="2618" type="application/vnd.observable.javascript">
    viewof showError = Inputs.toggle({
      label: "show error?",
      value: true
    })
  </script>
  <script id="1360" type="application/vnd.observable.javascript">
    Plot.plot({
      y: {
        domain: [0, 1]
      },
      marks: [
        showTemplate
          ? Plot.lineY(fitData, { x: "x", y: "template", stroke: "green" })
          : undefined,
        showScan
          ? Plot.lineY(fitData, { x: "x", y: "scan", stroke: "blue" })
          : undefined,
        showError
          ? Plot.lineY(fitData, { x: "x", y: "error", stroke: "red" })
          : undefined,
        Plot.ruleY([meanError], { stroke: "black" }),
        Plot.text([{ meanError, text: "mean\nerror" }], {
          x: width,
          y: (d) => d.meanError + 0.03,
          text: "text"
        })
      ]
    })
  </script>
  <script id="1464" type="text/markdown">
    ## Grid searching a best fit
    #### ⚠️ slow!
  </script>
  <script id="2829" type="text/markdown">
    A simple way of template matching is exhaustively trying all the pose combinations. However, this is a three-dimensional problem with an ${tex`O(n^4)`} time complexity. My computer can handle 50 steps per dimension, but this is not high enough to solve the problem without help. I have had luck using 5 steps per dim interactively, manually trimming the search space, then following up with a high step per dimension to get the best match in a small search space. Remember to turn off grid search so you can then fine-tune the final estimate.
  </script>
  <script id="1497" type="application/vnd.observable.javascript">
    viewof useBestFit = Inputs.toggle({
      label: "Use grid search"
    })
  </script>
  <script id="1466" type="application/vnd.observable.javascript">
    viewof steps = Inputs.range([1, 50], {
      value: 5,
      step: 1,
      label: "steps per dim"
    })
  </script>
  <script id="1549" type="application/vnd.observable.javascript">
    viewof offset_range = interval([-0.4, 0.4], {
      label: "offset range"
    })
  </script>
  <script id="1516" type="application/vnd.observable.javascript">
    viewof scale_range = interval([0, 1.5], {
      value: [0.1, 1.5],
      label: "scale range"
    })
  </script>
  <script id="1543" type="application/vnd.observable.javascript">
    viewof angle_range = interval([-Math.PI / 2 + 0.1, Math.PI / 2 - 0.1], {
      label: "angle range"
    })
  </script>
  <script id="1504" type="application/vnd.observable.javascript">
    doBestFit = {
      if (useBestFit) {
        viewof offset_pinhole.value = bestFit.offset;
        viewof scale_pinhole.value = bestFit.scale;
        viewof angle_pinhole.value = bestFit.angle;

        viewof offset_pinhole.dispatchEvent(new Event("input"));
        viewof scale_pinhole.dispatchEvent(new Event("input"));
        viewof angle_pinhole.dispatchEvent(new Event("input"));
      }
    }
  </script>
  <script id="1462" type="application/vnd.observable.javascript">
    bestFit = {
      if (!useBestFit) return this;
      let lowestError = Number.POSITIVE_INFINITY;
      let lowestParams = undefined;
      for (
        let offset = offset_range[0];
        offset <= offset_range[1];
        offset += (offset_range[1] - offset_range[0]) / steps
      )
        for (
          let scale = scale_range[0];
          scale <= scale_range[1];
          scale += (scale_range[1] - scale_range[0]) / steps
        )
          for (
            let angle = angle_range[0];
            angle <= angle_range[1];
            angle += (angle_range[1] - angle_range[0]) / steps
          ) {
            const params = {
              angle,
              scale,
              offset
            };
            const sumSquaredError = score_template_fit(params);
            if (sumSquaredError < lowestError) {
              lowestError = sumSquaredError;
              lowestParams = {
                ...params,
                sumSquaredError: sumSquaredError
              };
            }
          }
      return lowestParams;
    }
  </script>
  <script id="1528" type="application/vnd.observable.javascript">
    import { interval } from "@mootari/range-slider"
  </script>
  <script id="1653" type="text/markdown">
    ## Fine-tune with Local Patch Search
  </script>
  <script id="2860" type="text/markdown">
    When in the vicinity of a good match, you can find tune with the following routine.
  </script>
  <script id="2837" type="application/vnd.observable.javascript">
    viewof precision_patch = Inputs.range([1, 5], { label: "precision", step: 1 })
  </script>
  <script id="1656" type="application/vnd.observable.javascript">
    step_size = Number.parseFloat(
      "0." +
        Array.from({ length: precision_patch - 1 })
          .map((_) => "0")
          .join("") +
        "1"
    )
  </script>
  <script id="1693" type="application/vnd.observable.javascript">
    current = ({
      offset: offset_pinhole,
      angle: angle_pinhole,
      scale: scale_pinhole
    })
  </script>
  <script id="1690" type="application/vnd.observable.javascript">
    Inputs.button("step", {
      reduce: () => {
        let currentScore = score_template_fit(current);
        let next = current;
        // look around
        for (let dim in current) {
          for (let extent = -10; extent <= 10; extent += 10) {
            const candidate = {
              ...current,
              [dim]: current[dim] + extent * step_size
            };
            const candidateScore = score_template_fit(candidate);
            if (candidateScore < currentScore) {
              currentScore = candidateScore;
              next = candidate;
            }
          }
        }
        // update params
        viewof offset_pinhole.value = next.offset;
        viewof scale_pinhole.value = next.scale;
        viewof angle_pinhole.value = next.angle;

        viewof offset_pinhole.dispatchEvent(new Event("input"));
        viewof scale_pinhole.dispatchEvent(new Event("input"));
        viewof angle_pinhole.dispatchEvent(new Event("input"));
      }
    })
  </script>
  <script id="2868" type="text/markdown">
    ## Results

    After lots of bug fixes, I am pleased that it is possible to achieve very good template matches, indicating the template is keyed in correctly and we can faithfully predict the template deformation for the camera model. This is true even with high field-of-view camera models and strangely orientated barcodes as shown below.

    <figure>
      ${await FileAttachment("image@9.png").image({width: 600})}
      <figcaption>I angled the barcode awkwardly to the scan line </figcaption>
    </figure>

    <figure>
      ${await FileAttachment("image@7.png").image({width: 400})}
      <figcaption>Mean error of 0.014 achieved on the barcode above. This is what a good fit looks like</figcaption>
    </figure>

    The theory that circular barcodes can be read at any pose works out! This demonstrates circular barcodes can reduce orientated object detection down to a 3-degree-of-freedom problem on a 1-dimensional slice, a drastic reduction in underlying problem complexity that fits hardware.


  </script>
  <script id="2898" type="text/markdown">
    ## Next steps

    Looking forward, I think intensity-based approaches are not going to scale well. So in future work, I will try a feature-based approach (e.g. edge detection) to avoid the expensive inner loop and explore a streaming algorithm to suit hardware implementation. Future work will be added to the [realtime optical positioning collection](https://observablehq.com/collection/@tomlarkworthy/realtime-optical-positioning) of notebooks.
  </script>
  <script id="2938" type="text/markdown">
    ---
  </script>
  <script id="2940" type="text/markdown">
    ##### extra stuff
  </script>
  <script id="3" type="application/vnd.observable.javascript">
    THREE = {
      const THREE = window.THREE = await require("three@0.99.0/build/three.min.js");
      await require("three@0.99.0/examples/js/controls/OrbitControls.js").catch(() => {});
      return THREE;
    }
  </script>
  <script id="2632" type="text/html">
    <details>
      <summary>synthetic image</summary>
      ${synthetic}
    </details>
  </script>
  <script id="2530" type="text/html">
    <svg width=1600 xmlns="http://www.w3.org/2000/svg" viewBox="-${template.length/2} -${template.length/2} ${template.length} ${template.length}">
      ${template.map((t, i) => i > template.length / 2 ? undefined : htl.svg`<circle cx="0" cy="0" r="${Math.abs(template.length/2 - i)}" fill="${t == true ? "white": "black"}" />`)}
    </svg>
  </script>
  <script id="52" type="application/vnd.observable.javascript">
    height = 401
  </script>
  <script id="375" type="application/vnd.observable.javascript">
    mutable renders = 0
  </script>
</notebook>
