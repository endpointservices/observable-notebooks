<!doctype html>
<notebook theme="air">
  <title>1 Million Row Parquet Challenge</title>
  <script id="0" type="text/markdown">
    # 1 Million Row Parquet Challenge
  </script>
  <script id="7" type="text/markdown">
    ## Datasets

    On Github, 2M rows https://github.com/tomlarkworthy/datasets of S&P 500 data ([Kaggle](https://www.kaggle.com/datasets/gratefuldata/intraday-stock-data-1-min-sp-500-200821?resource=download)). Multiple symbols, so we can exploit parquet format to pull columns. Uncompressed dataset is 138.77 MB, most of the compression algorithms get to about 35 MB.

    I have tried out DuckDb and Hyparquet.
  </script>
  <script id="172" type="application/vnd.observable.javascript" pinned="">
    viewof compression = Inputs.select(["zstd", "gzip", "snappy", "br"], {
      label: "compression"
    })
  </script>
  <script id="36" type="application/vnd.observable.javascript">
    PARQUET_URL = `https://tomlarkworthy.github.io/datasets/1_min_SPY_2008-2021.${compression}.parquet`
  </script>
  <script id="182" type="text/markdown">
    # DuckDB
  </script>
  <script id="103" type="text/markdown">
    # Results

    In dev tools disable cache and load page, order by size. In my system duckdb issues range queries (206) to reduce transfers.

    DuckDB.wasm + its parquet extension itself is biggest download at 7.6Mb

    Despite the underlying datasets being 138Mb uncompressed, 35Mb compressed, only 6MB is transfered for 1M rows.

    It took 6 seconds to transfer the data (my internet or Github is slow)
    It takes 5 seconds on my machine to fully render a scatter of that and my browser goes jerky when the page reflows (the SVG is heavy)
    It only takes 0.3 to render a histogram of the same 1M datapoints.

    DuckDB is not the only library that can use range queries to slice parquet files, so the 7MB might be avoidable.
  </script>
  <script id="189" type="application/vnd.observable.javascript">
    viewof duckdb = Inputs.toggle({ label: "do duckdb" })
  </script>
  <script id="101" type="application/vnd.observable.javascript">
    image = FileAttachment("image.png").image()
  </script>
  <script id="67" type="text/markdown">
    ## DuckDB is 7MB :S
  </script>
  <script id="56" type="application/vnd.observable.javascript">
    import { DuckDBClient_latest as DuckDBClient } from "@mootari/duckdbclient"
  </script>
  <script id="28" type="application/vnd.observable.javascript">
    db = DuckDBClient.of({})
  </script>
  <script id="40" type="text/markdown">
    ## Getting the metadata is instant!

    It is *not* loading 37MB
  </script>
  <script id="33" type="application/sql" database="var:db">
    DESCRIBE SELECT * FROM parquet_scan(${PARQUET_URL})
  </script>
  <script id="71" type="text/markdown">
    ## Draw a 1M scatter plot
  </script>
  <script id="73" type="application/vnd.observable.javascript" pinned="">
    average_time = {
      if (!duckdb) throw "Enable Duck DB";
      const startTime = performance.now();
      const result = (
        await db.query(
          `SELECT average, date FROM parquet_scan('${PARQUET_URL}') LIMIT 1000000`
        )
      ).map((r) => ({ ...r, date: parseCustomDate(r.date) }));
      result.fetchTime = performance.now() - startTime;
      return result;
    }
  </script>
  <script id="147" type="application/vnd.observable.javascript" pinned="">
    average_time.fetchTime
  </script>
  <script id="89" type="application/vnd.observable.javascript">
    function parseCustomDate(dateString) {
      // Trim and split on one or more whitespace characters
      const [datePart, timePart] = dateString.trim().split(/\s+/);

      // Extract year, month, day from the datePart (YYYYMMDD)
      const year = parseInt(datePart.slice(0, 4), 10);
      const month = parseInt(datePart.slice(4, 6), 10) - 1; // JS months are 0-indexed
      const day = parseInt(datePart.slice(6, 8), 10);

      // Extract hours, minutes, seconds from the timePart (HH:MM:SS)
      const [hours, minutes, seconds] = timePart.split(":").map(Number);

      // Create and return the Date object (local time)
      return new Date(year, month, day, hours, minutes, seconds);
    }
  </script>
  <script id="288" type="text/markdown">
    # Visualizations
  </script>
  <script id="290" type="application/vnd.observable.javascript">
    viewof do_scatter = Inputs.toggle({ label: "draw scatter (slow!)" })
  </script>
  <script id="109" type="application/vnd.observable.javascript" pinned="">
    scatter = {
      if (!do_scatter) return;
      const startTime = performance.now();

      const plot = Plot.plot({
        marks: [Plot.dot(average_time, { x: "date", y: "average", tip: true })]
      });

      plot.renderTime = performance.now() - startTime;

      return plot;
    }
  </script>
  <script id="117" type="application/vnd.observable.javascript" pinned="">
    do_scatter && scatter.renderTime
  </script>
  <script id="126" type="application/vnd.observable.javascript" pinned="">
    histogram = {
      const startTime = performance.now();
      const plot = Plot.plot({
        marks: [
          Plot.rectY(average_time, Plot.binX({ y: "count" }, { x: "average" })),
          Plot.ruleY([0])
        ]
      });
      plot.renderTime = performance.now() - startTime;
      return plot;
    }
  </script>
  <script id="136" type="application/vnd.observable.javascript" pinned="">
    histogram.renderTime
  </script>
  <script id="153" type="application/vnd.observable.javascript" pinned="">
    density = {
      const startTime = performance.now();

      const plot = Plot.plot({
        marks: [
          Plot.density(average_time, {
            x: "date",
            y: "average",
            stroke: "blue",
            strokeWidth: 0.25
          })
        ]
      });

      plot.renderTime = performance.now() - startTime;

      return plot;
    }
  </script>
  <script id="158" type="application/vnd.observable.javascript" pinned="">
    density.renderTime
  </script>
  <script id="160" type="application/vnd.observable.javascript" pinned="">
    binned = {
      const startTime = performance.now();

      const plot = Plot.plot({
        marks: [Plot.rect(average_time, Plot.bin({}, { x: "date", y: "average" }))]
      });

      plot.renderTime = performance.now() - startTime;

      return plot;
    }
  </script>
  <script id="164" type="application/vnd.observable.javascript" pinned="">
    binned.renderTime
  </script>
  <script id="184" type="text/markdown">
    # Hyparquet

    Hyparquet is much faster than DuckDB at reading and converting, but it will do a single range query for two columns, even if it makes sense to do two seperate ranges, so you need to split your column reads which does provide the opertunity for parrellelization
  </script>
  <script id="186" type="application/vnd.observable.javascript">
    hyparquet = import("https://cdn.jsdelivr.net/npm/hyparquet@1.17.8/+esm")
  </script>
  <script id="206" type="application/vnd.observable.javascript">
    compressors = import(
      "https://cdn.jsdelivr.net/npm/hyparquet-compressors@1.1.1/+esm"
    )
  </script>
  <script id="195" type="application/vnd.observable.javascript">
    viewof hypa_read_objects = Inputs.toggle({ label: "do hypa_read_objects" })
  </script>
  <script id="279" type="application/vnd.observable.javascript" pinned="">
    start_time = hypa_read_objects && performance.now()
  </script>
  <script id="199" type="application/vnd.observable.javascript" pinned="">
    hypa_data_date = {
      if (!hypa_read_objects) throw "enable hyparquet";
      const file = await hyparquet.asyncBufferFromUrl({ url: PARQUET_URL }); // wrap url for async fetching
      const startTime = performance.now();
      const data = await hyparquet.parquetReadObjects({
        file,
        columns: ["date"],
        rowStart: 0,
        rowEnd: 1000000, // These don't affect data read! we need rowLimit
        compressors: compressors.compressors
      });

      const fetchTime = performance.now() - startTime;
      const munged = data.map((r) => ({ date: parseCustomDate(r.date) }));
      munged.mungeTime = performance.now() - startTime;
      munged.fetchTime = fetchTime;
      return munged;
    }
  </script>
  <script id="307" type="application/vnd.observable.javascript" pinned="">
    PARQUET_URL
  </script>
  <script id="267" type="application/vnd.observable.javascript" pinned="">
    hypa_data_average = {
      if (!hypa_read_objects) return [];
      const file = await hyparquet.asyncBufferFromUrl({ url: PARQUET_URL }); // wrap url for async fetching
      const startTime = performance.now();
      const data = await hyparquet.parquetReadObjects({
        file,
        columns: ["average"],
        rowStart: 0,
        rowEnd: 1000000, // These don't affect data read! we need rowLimit
        compressors: compressors.compressors
      });

      data.fetchTime = performance.now() - startTime;
      return data;
    }
  </script>
  <script id="223" type="application/vnd.observable.javascript" pinned="">
    hypa_data_date.fetchTime
  </script>
  <script id="271" type="application/vnd.observable.javascript" pinned="">
    hypa_data_average.fetchTime
  </script>
  <script id="215" type="application/vnd.observable.javascript" pinned="">
    hypa_data_date.mungeTime
  </script>
  <script id="282" type="application/vnd.observable.javascript" pinned="">
    total_time = hypa_data_average &&
      hypa_data_date &&
      performance.now() - start_time
  </script>
</notebook>
